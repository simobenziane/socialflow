{
    "name":  "W1: Ingest \u0026 Validate v16",
    "nodes":  [
                  {
                      "parameters":  {
                                         "httpMethod":  "POST",
                                         "path":  "w1-ingest",
                                         "responseMode":  "responseNode",
                                         "options":  {

                                                     }
                                     },
                      "type":  "n8n-nodes-base.webhook",
                      "typeVersion":  2.1,
                      "position":  [
                                       -240,
                                       112
                                   ],
                      "id":  "ec577bfa-d414-4642-8906-e9e70cae9403",
                      "name":  "Webhook Trigger",
                      "webhookId":  "w1-ingest",
                      "onError":  "continueRegularOutput"
                  },
                  {
                      "parameters":  {
                                         "jsCode":  "/**\n * W1 v16: Load Config (YAML)\n * Reads client/batch from payload or active_job.json\n * Loads client.yaml and batch.yaml configurations\n * v15: Added Ollama config for image description\n * v15.1: Added VLM resize config\n */\nconst fs = require(\u0027fs\u0027);\nconst yaml = require(\u0027js-yaml\u0027);\n\nconsole.log(\u0027[W1] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u0027);\nconsole.log(\u0027[W1] Starting Ingest \u0026 Validate v16\u0027);\nconsole.log(\u0027[W1] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u0027);\n\nconst input = $input.first().json || {};\nconst CONFIG_BASE = \u0027/data/clients/_config\u0027;\nconst SETTINGS_PATH = `${CONFIG_BASE}/settings.json`;\nconst ACTIVE_JOB_PATH = `${CONFIG_BASE}/active_job.json`;\nconst DB_PATH = `${CONFIG_BASE}/socialflow.db`;\n\nlet CLIENT, BATCH;\n\n// Priority: webhook payload \u003e active_job.json\nif (input.client || input.body?.client) {\n  CLIENT = input.client || input.body?.client;\n  BATCH = input.batch || input.body?.batch;\n  console.log(`[W1] â„¹ Using webhook payload: ${CLIENT}/${BATCH}`);\n} else {\n  try {\n    const activeJob = JSON.parse(fs.readFileSync(ACTIVE_JOB_PATH, \u0027utf8\u0027));\n    CLIENT = activeJob.current?.client || activeJob.client;\n    BATCH = activeJob.current?.batch || activeJob.batch;\n    console.log(`[W1] â„¹ Using active_job.json: ${CLIENT}/${BATCH}`);\n  } catch (e) {\n    console.log(\u0027[W1] âœ— [CONFIG_MISSING] Cannot read active_job.json\u0027);\n    return [{\n      json: {\n        _error: true,\n        error_code: \u0027CONFIG_MISSING\u0027,\n        error_message: `Cannot determine client/batch. Send {client, batch} in webhook or create ${ACTIVE_JOB_PATH}`,\n        _start_time: Date.now(),\n        _config_base: CONFIG_BASE\n      }\n    }];\n  }\n}\n\nif (!CLIENT || !BATCH) {\n  console.log(\u0027[W1] âœ— [CONFIG_MISSING] Missing client or batch\u0027);\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027CONFIG_MISSING\u0027,\n      error_message: \u0027Both client and batch are required\u0027,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\n\n// Security: Validate slugs contain only safe characters (prevent path traversal)\nconst SAFE_SLUG = /^[a-zA-Z0-9_-]+$/;\nif (!SAFE_SLUG.test(CLIENT) || !SAFE_SLUG.test(BATCH)) {\n  console.log(\u0027[W1] âœ— [INVALID_SLUG] Invalid characters in client/batch slug\u0027);\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027INVALID_SLUG\u0027,\n      error_message: `Invalid slug format. CLIENT=${CLIENT}, BATCH=${BATCH}. Only alphanumeric, dash, and underscore allowed.`,\n      client: CLIENT,\n      batch: BATCH,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\nconsole.log(\u0027[W1] âœ“ Slug validation passed\u0027);\n\n// Load settings\nlet settings;\ntry {\n  if (!fs.existsSync(SETTINGS_PATH)) {\n    return [{\n      json: {\n        _error: true,\n        error_code: \u0027CONFIG_MISSING\u0027,\n        error_message: `settings.json not found at ${SETTINGS_PATH}`,\n        client: CLIENT,\n        batch: BATCH,\n        _start_time: Date.now(),\n        _config_base: CONFIG_BASE\n      }\n    }];\n  }\n  settings = JSON.parse(fs.readFileSync(SETTINGS_PATH, \u0027utf8\u0027));\n  console.log(\u0027[W1] âœ“ settings.json loaded\u0027);\n} catch (e) {\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027CONFIG_MISSING\u0027,\n      error_message: `Cannot parse settings.json: ${e.message}`,\n      client: CLIENT,\n      batch: BATCH,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\n\n// Validate Cloudflare URL\nconst CLOUDFLARE_URL = settings.cloudflare_tunnel_url;\nif (!CLOUDFLARE_URL || CLOUDFLARE_URL.includes(\u0027PASTE-YOUR-TUNNEL\u0027) || CLOUDFLARE_URL.includes(\u0027your-tunnel\u0027)) {\n  console.log(\u0027[W1] âœ— [CONFIG_MISSING] Cloudflare URL not configured\u0027);\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027CONFIG_MISSING\u0027,\n      error_message: \u0027Cloudflare tunnel URL not configured! Run cloudflared and update settings.json\u0027,\n      client: CLIENT,\n      batch: BATCH,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\n\nif (!CLOUDFLARE_URL.startsWith(\u0027https://\u0027)) {\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027CONFIG_MISSING\u0027,\n      error_message: \u0027cloudflare_tunnel_url must start with https://\u0027,\n      client: CLIENT,\n      batch: BATCH,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\n\nconsole.log(`[W1] âœ“ Cloudflare URL: ${CLOUDFLARE_URL.substring(0, 50)}...`);\n\n// Load Ollama config for image description (v15)\nconst OLLAMA_URL = settings.ollama?.url_docker || \u0027http://host.docker.internal:11434/api/generate\u0027;\nconst IMAGE_DESCRIBER_MODEL = settings.ollama?.models?.image_describer || settings.ollama?.model || \u0027llava:7b\u0027;\nconst DESCRIPTION_TIMEOUT = settings.caption_generation?.description_timeout_ms || 60000;\n\n// v15.1: VLM resize settings - resize large images before sending to VLM\nconst VLM_RESIZE_MAX = settings.vlm?.resize_max_dimension || 1024;\nconst VLM_RESIZE_QUALITY = settings.vlm?.resize_quality || 85;\nconst VLM_RESIZE_ENABLED = settings.vlm?.resize_enabled !== false; // default true\n\nconsole.log(`[W1] âœ“ Image describer: ${IMAGE_DESCRIBER_MODEL}`);\nconsole.log(`[W1] âœ“ VLM resize: ${VLM_RESIZE_ENABLED ? `enabled (max ${VLM_RESIZE_MAX}px, quality ${VLM_RESIZE_QUALITY})` : \u0027disabled\u0027}`);\n\n// Load client.yaml\nconst LOCAL_BASE = settings.paths.docker_base;\nconst clientRoot = `${LOCAL_BASE}/${CLIENT}`;\nconst clientYamlPath = `${clientRoot}/client.yaml`;\n\nlet clientConfig;\ntry {\n  if (!fs.existsSync(clientYamlPath)) {\n    return [{\n      json: {\n        _error: true,\n        error_code: \u0027CLIENT_NOT_FOUND\u0027,\n        error_message: `Client not found: ${CLIENT}. No client.yaml at ${clientYamlPath}`,\n        client: CLIENT,\n        batch: BATCH,\n        _start_time: Date.now(),\n        _config_base: CONFIG_BASE\n      }\n    }];\n  }\n  clientConfig = yaml.load(fs.readFileSync(clientYamlPath, \u0027utf8\u0027));\n  console.log(`[W1] âœ“ client.yaml loaded for ${clientConfig.name || CLIENT}`);\n} catch (e) {\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027YAML_PARSE_ERROR\u0027,\n      error_message: `Cannot parse client.yaml: ${e.message}`,\n      client: CLIENT,\n      batch: BATCH,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\n\nif (clientConfig.is_active === false) {\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027CLIENT_NOT_FOUND\u0027,\n      error_message: `Client \"${CLIENT}\" is not active. Set is_active: true in client.yaml`,\n      client: CLIENT,\n      batch: BATCH,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\n\n// Load batch.yaml (auto-create if missing - v15.2)\nconst batchRoot = `${clientRoot}/${BATCH}`;\nconst batchYamlPath = `${batchRoot}/batch.yaml`;\n\nlet batchConfig;\ntry {\n  // v15.2: Auto-create batch.yaml if missing\n  if (!fs.existsSync(batchYamlPath)) {\n    if (!fs.existsSync(batchRoot)) {\n      return [{\n        json: {\n          _error: true,\n          error_code: \u0027BATCH_NOT_FOUND\u0027,\n          error_message: `Batch folder not found: ${batchRoot}`,\n          client: CLIENT,\n          batch: BATCH,\n          _start_time: Date.now(),\n          _config_base: CONFIG_BASE\n        }\n      }];\n    }\n    // Auto-generate minimal batch.yaml\n    const today = new Date().toISOString().split(\u0027T\u0027)[0];\n    const minimalYaml = `# Auto-generated batch config (v15.2)\\nname: \"${BATCH}\"\\ndescription: \"Auto-created batch\"\\n\\nbrief: |\\n  Content for ${BATCH} batch.\\n\\nhashtags:\\n  - \"#${CLIENT.replace(/-/g, \u0027\u0027)}\"\\n\\nschedule:\\n  start_date: \"${today}\"\\n  strategy:\\n    type: \"daily\"\\n    max_per_day: 1\\n  distribution:\\n    mode: \"photos_first\"\\n  defaults:\\n    feed_time: \"19:00\"\\n    story_time: \"12:00\"\\n\\nslot: \"feed\"\\n`;\n    fs.writeFileSync(batchYamlPath, minimalYaml);\n    console.log(\u0027[W1] âœ“ Auto-created batch.yaml for \u0027 + BATCH);\n  }\n  batchConfig = yaml.load(fs.readFileSync(batchYamlPath, \u0027utf8\u0027));\n  console.log(`[W1] âœ“ batch.yaml loaded: ${batchConfig.name || BATCH}`);\n} catch (e) {\n  return [{\n    json: {\n      _error: true,\n      error_code: \u0027YAML_PARSE_ERROR\u0027,\n      error_message: `Cannot parse batch.yaml: ${e.message}`,\n      client: CLIENT,\n      batch: BATCH,\n      _start_time: Date.now(),\n      _config_base: CONFIG_BASE\n    }\n  }];\n}\n\n// Helper to get default account ID\nfunction getDefaultAccountId(accounts, platform) {\n  if (!accounts || !accounts[platform]) return \u0027\u0027;\n  const platformAccounts = accounts[platform];\n  if (Array.isArray(platformAccounts)) {\n    const defaultAcc = platformAccounts.find(a =\u003e a.is_default) || platformAccounts[0];\n    return defaultAcc?.late_account_id || \u0027\u0027;\n  }\n  return platformAccounts.late_account_id || \u0027\u0027;\n}\n\nconst INSTAGRAM_ACCOUNT_ID = getDefaultAccountId(clientConfig.accounts, \u0027instagram\u0027);\nconst TIKTOK_ACCOUNT_ID = getDefaultAccountId(clientConfig.accounts, \u0027tiktok\u0027);\nconst TIMEZONE = clientConfig.timezone || settings.defaults?.timezone || \u0027Europe/Berlin\u0027;\nconst LANGUAGE = clientConfig.language || settings.defaults?.language || \u0027fr\u0027;\nconst FEED_TIME = batchConfig.schedule?.defaults?.feed_time || settings.defaults?.feed_time || \u002720:00\u0027;\nconst STORY_TIME = batchConfig.schedule?.defaults?.story_time || settings.defaults?.story_time || \u002718:30\u0027;\n\nconst PLATFORM_DEFAULTS = batchConfig.platforms || clientConfig.platform_defaults || {\n  photos: { feed: \u0027ig\u0027, story: \u0027ig\u0027 },\n  videos: { feed: \u0027ig,tt\u0027, story: \u0027ig\u0027 }\n};\n\nconst POLICY = clientConfig.policy || {\n  require_video_frames: true,\n  video_frames_required: 4,\n  require_cover_image: false,\n  tiktok_video_only: true,\n  story_requires_story_asset: false\n};\n\n// Merge hashtags (client + batch)\nconst clientHashtags = clientConfig.hashtags || [];\nconst batchHashtags = batchConfig.hashtags || [];\nconst allHashtags = [...clientHashtags, ...batchHashtags]\n  .map(h =\u003e h.trim())\n  .filter(h =\u003e h.length \u003e 0)\n  .map(h =\u003e h.startsWith(\u0027#\u0027) ? h : `#${h}`);\nconst uniqueHashtags = [...new Set(allHashtags.map(h =\u003e h.toLowerCase()))]\n  .map(lower =\u003e allHashtags.find(h =\u003e h.toLowerCase() === lower));\n\nconsole.log(`[W1] âœ“ Hashtags: ${uniqueHashtags.length} (client: ${clientHashtags.length}, batch: ${batchHashtags.length})`);\n\n// Build schedule config\nconst schedule = {\n  start_date: batchConfig.schedule?.start_date || new Date().toISOString().split(\u0027T\u0027)[0],\n  timezone: TIMEZONE,\n  defaults: { feed_time: FEED_TIME, story_time: STORY_TIME },\n  strategy: {\n    type: batchConfig.schedule?.strategy?.type || \u0027daily\u0027,\n    interval_days: batchConfig.schedule?.strategy?.interval_days || 1,\n    weekdays: batchConfig.schedule?.strategy?.weekdays || [],\n    dates: batchConfig.schedule?.strategy?.dates || [],\n    max_per_day: batchConfig.schedule?.strategy?.max_per_day || 1,\n    distribution: { mode: batchConfig.schedule?.distribution?.mode || \u0027alternate\u0027 }\n  },\n  platforms: PLATFORM_DEFAULTS,\n  slot: batchConfig.slot || \u0027feed\u0027,\n  overrides: batchConfig.overrides || []\n};\n\nconsole.log(`[W1] âœ“ Schedule: type=${schedule.strategy.type}, start=${schedule.start_date}`);\n\nconst mediaBaseUrl = `${CLOUDFLARE_URL}/${CLIENT}/${BATCH}`;\nconsole.log(`[W1] â„¹ Batch root: ${batchRoot}`);\nconsole.log(`[W1] â„¹ Media URL: ${mediaBaseUrl}`);\n\n// v16: Get source_type from database if batch exists there\nlet SOURCE_TYPE = \u0027folder\u0027;\ntry {\n  const Database = require(\u0027better-sqlite3\u0027);\n  const db = new Database(DB_PATH);\n  const clientRow = db.prepare(\u0027SELECT id FROM clients WHERE slug = ?\u0027).get(CLIENT);\n  if (clientRow) {\n    const batchRow = db.prepare(\u0027SELECT source_type FROM batches WHERE client_id = ? AND slug = ?\u0027).get(clientRow.id, BATCH);\n    if (batchRow \u0026\u0026 batchRow.source_type) {\n      SOURCE_TYPE = batchRow.source_type;\n      console.log(`[W1] âœ“ Source type from database: ${SOURCE_TYPE}`);\n    }\n  }\n  db.close();\n} catch (e) {\n  console.log(`[W1] âš  Could not check source_type: ${e.message}`);\n}\n\nreturn [{\n  json: {\n    client_slug: CLIENT,\n    batch_name: BATCH,\n    cloudflare_url: CLOUDFLARE_URL,\n    local_base: LOCAL_BASE,\n    batch_root: batchRoot,\n    client_root: clientRoot,\n    media_base_url: mediaBaseUrl,\n    ready_path: `${batchRoot}/READY.txt`,\n    photos_dir: `${batchRoot}/photos`,\n    videos_dir: `${batchRoot}/videos`,\n    instagram_account_id: INSTAGRAM_ACCOUNT_ID,\n    tiktok_account_id: TIKTOK_ACCOUNT_ID,\n    timezone: TIMEZONE,\n    language: LANGUAGE,\n    feed_time: FEED_TIME,\n    story_time: STORY_TIME,\n    platform_defaults: PLATFORM_DEFAULTS,\n    policy: POLICY,\n    db_path: DB_PATH,\n    source_type: SOURCE_TYPE,\n    schedule,\n    hashtags_list: uniqueHashtags,\n    hashtags_joined: uniqueHashtags.join(\u0027 \u0027),\n    client_config: clientConfig,\n    batch_config: batchConfig,\n    brief: batchConfig.brief || \u0027\u0027,\n    _start_time: Date.now(),\n    _source: input.body ? \u0027webhook\u0027 : \u0027manual\u0027,\n    _ingest_id: `ingest_${Date.now()}_${Math.random().toString(36).substr(2, 6)}`,\n    _config_base: CONFIG_BASE,\n    _ollama_url: OLLAMA_URL,\n    _image_describer_model: IMAGE_DESCRIBER_MODEL,\n    _description_timeout: DESCRIPTION_TIMEOUT,\n    _vlm_resize_enabled: VLM_RESIZE_ENABLED,\n    _vlm_resize_max: VLM_RESIZE_MAX,\n    _vlm_resize_quality: VLM_RESIZE_QUALITY,\n    _error: false\n  }\n}];"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       0,
                                       0
                                   ],
                      "id":  "87f6a9da-867d-4ce8-b727-57d2adf40a43",
                      "name":  "Load Config (YAML)"
                  },
                  {
                      "parameters":  {
                                         "jsCode":  "/**\n * W1 v16: Validate Context\n * Checks READY.txt, brief, and database existence\n */\nconst fs = require(\u0027fs\u0027);\nconst crypto = require(\u0027crypto\u0027);\nconst config = $input.first().json;\n\nif (config._error) {\n  return [{ json: config }];\n}\n\n// Check READY.txt exists (skip for upload batches - v16)\nif (config.source_type !== \u0027upload\u0027) {\n  if (!fs.existsSync(config.ready_path)) {\n    console.log(\u0027[W1] âœ— [READY_FILE_MISSING] READY.txt not found\u0027);\n    return [{\n      json: {\n        ...config,\n        _error: true,\n        error_code: \u0027READY_FILE_MISSING\u0027,\n        error_message: `READY.txt not found at ${config.ready_path}. Batch is not ready for processing.`\n      }\n    }];\n  }\n  console.log(\u0027[W1] âœ“ READY.txt found\u0027);\n} else {\n  console.log(\u0027[W1] â„¹ Skipping READY.txt check (upload batch)\u0027);\n}\n\n// Validate brief\nif (!config.brief || config.brief.trim() === \u0027\u0027) {\n  console.log(\u0027[W1] âš  No brief found in batch.yaml, using default\u0027);\n  config.brief = \u0027Content for social media. Professional, engaging tone.\u0027;\n}\n\nconst briefHash = crypto.createHash(\u0027md5\u0027).update(config.brief).digest(\u0027hex\u0027);\nconsole.log(`[W1] âœ“ Brief loaded (${config.brief.length} chars)`);\nconsole.log(`[W1] âœ“ Hashtags: ${config.hashtags_list.length} tags`);\n\n// Verify database exists\nif (!fs.existsSync(config.db_path)) {\n  console.log(\u0027[W1] âœ— [DB_NOT_FOUND] Database not found\u0027);\n  return [{\n    json: {\n      ...config,\n      _error: true,\n      error_code: \u0027DB_NOT_FOUND\u0027,\n      error_message: `Database not found at ${config.db_path}. Run init_database.js first.`\n    }\n  }];\n}\nconsole.log(\u0027[W1] âœ“ Database found\u0027);\n\nreturn [{ json: { ...config, brief_hash: briefHash } }];"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       240,
                                       0
                                   ],
                      "id":  "f6247e92-57cf-4673-a80a-c372293ca075",
                      "name":  "Validate Context"
                  },
                  {
                      "parameters":  {
                                         "jsCode":  "/**\n * W1 v16: Auto-Discover \u0026 Schedule\n * Discovers media files and assigns schedule dates\n * v15.3: Include batch name in content_id for batch isolation\n */\nconst fs = require(\u0027fs\u0027);\nconst crypto = require(\u0027crypto\u0027);\nconst ctx = $input.first().json;\n\nif (ctx._error) {\n  return [{ json: ctx }];\n}\n\nconst PHOTO_EXTENSIONS = [\u0027.jpg\u0027, \u0027.jpeg\u0027, \u0027.png\u0027, \u0027.webp\u0027];\nconst VIDEO_EXTENSIONS = [\u0027.mp4\u0027, \u0027.mov\u0027, \u0027.webm\u0027];\nconst FRAME_PATTERN_NEW = /_F([1-4])$/i;\nconst FRAME_PATTERN_OLD = /__F([1-4])$/i;\nconst COVER_PATTERN_NEW = /_COVER$/i;\nconst COVER_PATTERN_OLD = /__COVER$/i;\nconst STORY_PATTERN_NEW = /_STORY$/i;\nconst STORY_PATTERN_OLD = /__STORY$/i;\n\nconst getExtension = (f) =\u003e {\n  const parts = f.split(\u0027.\u0027);\n  return parts.length \u003e 1 ? \u0027.\u0027 + parts.pop().toLowerCase() : \u0027\u0027;\n};\n\nconst getBasename = (f) =\u003e {\n  const parts = f.split(\u0027.\u0027);\n  if (parts.length \u003e 1) parts.pop();\n  return parts.join(\u0027.\u0027);\n};\n\nconst isFrameFile = (b) =\u003e FRAME_PATTERN_NEW.test(b) || FRAME_PATTERN_OLD.test(b);\nconst isCoverFile = (b) =\u003e COVER_PATTERN_NEW.test(b) || COVER_PATTERN_OLD.test(b);\nconst isStoryFile = (b) =\u003e STORY_PATTERN_NEW.test(b) || STORY_PATTERN_OLD.test(b);\nconst getVideoBaseFromFrame = (b) =\u003e b.replace(/_F[1-4]$/i, \u0027\u0027).replace(/__F[1-4]$/i, \u0027\u0027);\nconst getVideoBaseFromCover = (b) =\u003e b.replace(/_COVER$/i, \u0027\u0027).replace(/__COVER$/i, \u0027\u0027);\n\n// v16: Check source_type for upload vs folder batches\nconst sourceType = ctx.source_type || \u0027folder\u0027;\nlet photos = [];\nlet videos = [];\nconst videoMap = new Map();\nconst deprecationWarnings = [];\n\nif (sourceType === \u0027upload\u0027) {\n  // Query files table for upload-based batches\n  try {\n    const Database = require(\u0027better-sqlite3\u0027);\n    const db = new Database(ctx.db_path);\n    const clientRow = db.prepare(\u0027SELECT id FROM clients WHERE slug = ?\u0027).get(ctx.client_slug);\n    const batchRow = db.prepare(\u0027SELECT id FROM batches WHERE client_id = ? AND slug = ?\u0027).get(clientRow?.id, ctx.batch_name);\n    if (batchRow) {\n      const files = db.prepare(\u0027SELECT id, original_name, storage_path, mime_type, file_size, checksum FROM files WHERE batch_id = ? AND status = ? ORDER BY uploaded_at\u0027).all(batchRow.id, \u0027ready\u0027);\n      for (const file of files) {\n        const isVideo = file.mime_type?.startsWith(\u0027video/\u0027);\n        if (isVideo) {\n          videos.push({ file: file.original_name, basename: file.original_name.replace(/\\\\.[^/.]+$/, \u0027\u0027), frames: [null, null, null, null], cover: null, story: null, _db_path: file.storage_path, _db_hash: file.checksum, _db_size: file.file_size, _file_id: file.id });\n        } else {\n          photos.push({ file: file.original_name, basename: file.original_name.replace(/\\\\.[^/.]+$/, \u0027\u0027), story: null, _db_path: file.storage_path, _db_hash: file.checksum, _db_size: file.file_size, _file_id: file.id });\n        }\n      }\n      console.log(`[W1] âœ“ Loaded ${files.length} files from database (source_type=upload)`);\n    }\n    db.close();\n  } catch (e) {\n    console.log(`[W1] âœ— Error loading files from database: ${e.message}`);\n  }\n}\n\n// Discover videos (folder-based batch)\nif (sourceType === \u0027folder\u0027) {\n\ntry {\n  if (fs.existsSync(ctx.videos_dir)) {\n    const allFiles = fs.readdirSync(ctx.videos_dir).sort();\n\n    // First pass: find video files\n    for (const file of allFiles) {\n      const ext = getExtension(file);\n      const basename = getBasename(file);\n      if (VIDEO_EXTENSIONS.includes(ext) \u0026\u0026 !isStoryFile(basename)) {\n        const video = { file, basename, frames: [null, null, null, null], cover: null, story: null };\n        videos.push(video);\n        videoMap.set(basename.toLowerCase(), video);\n      }\n    }\n\n    // Second pass: associate frames, covers, stories\n    for (const file of allFiles) {\n      const ext = getExtension(file);\n      const basename = getBasename(file);\n      const fullPath = `${ctx.videos_dir}/${file}`;\n\n      if (PHOTO_EXTENSIONS.includes(ext) \u0026\u0026 isFrameFile(basename)) {\n        const videoBase = getVideoBaseFromFrame(basename).toLowerCase();\n        const video = videoMap.get(videoBase);\n        if (video) {\n          const matchNew = basename.match(FRAME_PATTERN_NEW);\n          const matchOld = basename.match(FRAME_PATTERN_OLD);\n          if (matchNew) {\n            video.frames[parseInt(matchNew[1]) - 1] = fullPath;\n          } else if (matchOld) {\n            video.frames[parseInt(matchOld[1]) - 1] = fullPath;\n            deprecationWarnings.push(`DEPRECATED: Use _F${matchOld[1]} instead of __F${matchOld[1]} for ${file}`);\n          }\n        }\n      } else if (PHOTO_EXTENSIONS.includes(ext) \u0026\u0026 isCoverFile(basename)) {\n        const videoBase = getVideoBaseFromCover(basename).toLowerCase();\n        const video = videoMap.get(videoBase);\n        if (video) {\n          video.cover = fullPath;\n          if (COVER_PATTERN_OLD.test(basename)) {\n            deprecationWarnings.push(`DEPRECATED: Use _COVER instead of __COVER for ${file}`);\n          }\n        }\n      } else if (VIDEO_EXTENSIONS.includes(ext) \u0026\u0026 isStoryFile(basename)) {\n        const mainBase = basename.replace(/_STORY$/i, \u0027\u0027).replace(/__STORY$/i, \u0027\u0027).toLowerCase();\n        const video = videoMap.get(mainBase);\n        if (video) {\n          video.story = fullPath;\n          if (STORY_PATTERN_OLD.test(basename)) {\n            deprecationWarnings.push(`DEPRECATED: Use _STORY instead of __STORY for ${file}`);\n          }\n        }\n      }\n    }\n    console.log(`[W1] âœ“ Discovered ${videos.length} videos`);\n  } else {\n    console.log(`[W1] âš  Videos directory not found: ${ctx.videos_dir}`);\n  }\n} catch (e) {\n  console.log(`[W1] âš  Error reading videos: ${e.message}`);\n}\n\n// Discover photos (folder-based batch)\ntry {\n  if (fs.existsSync(ctx.photos_dir)) {\n    const allFiles = fs.readdirSync(ctx.photos_dir).sort();\n\n    for (const file of allFiles) {\n      const ext = getExtension(file);\n      const basename = getBasename(file);\n      if (PHOTO_EXTENSIONS.includes(ext) \u0026\u0026 !isStoryFile(basename)) {\n        photos.push({ file, basename, story: null });\n      }\n    }\n\n    // Associate stories\n    for (const file of allFiles) {\n      const ext = getExtension(file);\n      const basename = getBasename(file);\n      if (PHOTO_EXTENSIONS.includes(ext) \u0026\u0026 isStoryFile(basename)) {\n        const mainBase = basename.replace(/_STORY$/i, \u0027\u0027).replace(/__STORY$/i, \u0027\u0027).toLowerCase();\n        const photo = photos.find(p =\u003e p.basename.toLowerCase() === mainBase);\n        if (photo) {\n          photo.story = `${ctx.photos_dir}/${file}`;\n          if (STORY_PATTERN_OLD.test(basename)) {\n            deprecationWarnings.push(`DEPRECATED: Use _STORY instead of __STORY for ${file}`);\n          }\n        }\n      }\n    }\n    console.log(`[W1] âœ“ Discovered ${photos.length} photos`);\n  } else {\n    console.log(`[W1] âš  Photos directory not found: ${ctx.photos_dir}`);\n  }\n} catch (e) {\n  console.log(`[W1] âš  Error reading photos: ${e.message}`);\n}\n} // end if (sourceType === \u0027folder\u0027)\n\nif (deprecationWarnings.length \u003e 0) {\n  console.log(`[W1] âš  ${deprecationWarnings.length} deprecation warnings`);\n}\n\nif (photos.length === 0 \u0026\u0026 videos.length === 0) {\n  console.log(\u0027[W1] âœ— [NO_ITEMS] No media files found\u0027);\n  return [{\n    json: {\n      ...ctx,\n      _error: true,\n      error_code: \u0027NO_ITEMS\u0027,\n      error_message: sourceType === \u0027upload\u0027 ? \u0027No ready files found in database for this batch. Ensure files were uploaded and processed.\u0027 : `No media files found in ${ctx.photos_dir} or ${ctx.videos_dir}. Ensure photos/ or videos/ directories contain valid media files.`\n    }\n  }];\n}\n\n// Scheduling functions\nfunction computeScheduleDates(schedule, totalItems) {\n  const dates = [];\n  let currentDate = new Date(schedule.start_date + \u0027T00:00:00\u0027);\n  let itemsScheduled = 0;\n  let iterations = 0;\n  const maxIterations = 365;\n\n  while (itemsScheduled \u003c totalItems \u0026\u0026 iterations \u003c maxIterations) {\n    iterations++;\n    let shouldPost = false;\n\n    switch (schedule.strategy.type) {\n      case \u0027daily\u0027: shouldPost = true; break;\n      case \u0027interval\u0027: shouldPost = (iterations - 1) % schedule.strategy.interval_days === 0; break;\n      case \u0027weekly\u0027: shouldPost = schedule.strategy.weekdays.includes(currentDate.getDay()); break;\n      case \u0027specific_dates\u0027: shouldPost = schedule.strategy.dates.includes(currentDate.toISOString().split(\u0027T\u0027)[0]); break;\n      default: shouldPost = true;\n    }\n\n    if (shouldPost) {\n      const itemsToday = Math.min(schedule.strategy.max_per_day, totalItems - itemsScheduled);\n      for (let i = 0; i \u003c itemsToday; i++) {\n        dates.push(currentDate.toISOString().split(\u0027T\u0027)[0]);\n        itemsScheduled++;\n      }\n    }\n    currentDate.setDate(currentDate.getDate() + 1);\n  }\n  return dates;\n}\n\nfunction sortFilesByDistribution(photos, videos, mode) {\n  const items = [];\n  switch (mode) {\n    case \u0027photos_first\u0027:\n      photos.forEach(p =\u003e items.push({ ...p, type: \u0027photo\u0027 }));\n      videos.forEach(v =\u003e items.push({ ...v, type: \u0027video\u0027 }));\n      break;\n    case \u0027videos_first\u0027:\n      videos.forEach(v =\u003e items.push({ ...v, type: \u0027video\u0027 }));\n      photos.forEach(p =\u003e items.push({ ...p, type: \u0027photo\u0027 }));\n      break;\n    case \u0027alternate\u0027:\n      const maxLen = Math.max(photos.length, videos.length);\n      for (let i = 0; i \u003c maxLen; i++) {\n        if (i \u003c photos.length) items.push({ ...photos[i], type: \u0027photo\u0027 });\n        if (i \u003c videos.length) items.push({ ...videos[i], type: \u0027video\u0027 });\n      }\n      break;\n    default: // mixed\n      photos.forEach(p =\u003e items.push({ ...p, type: \u0027photo\u0027 }));\n      videos.forEach(v =\u003e items.push({ ...v, type: \u0027video\u0027 }));\n      items.sort((a, b) =\u003e a.file.localeCompare(b.file));\n  }\n  return items;\n}\n\nfunction computeFileHash(filePath) {\n  try {\n    if (fs.existsSync(filePath)) {\n      return crypto.createHash(\u0027md5\u0027).update(fs.readFileSync(filePath)).digest(\u0027hex\u0027);\n    }\n  } catch (e) {}\n  return \u0027\u0027;\n}\n\nfunction generateContentId(clientSlug, batchName, date, slot, mediaType, index) {\n  const dateClean = date.replace(/-/g, \u0027\u0027);\n  const seq = String(index + 1).padStart(2, \u00270\u0027);\n  return `${clientSlug}__${batchName}__${dateClean}__${slot}__${mediaType}__${seq}`;\n}\n\n// Build items\nconst sortedItems = sortFilesByDistribution(photos, videos, ctx.schedule.strategy.distribution?.mode || \u0027alternate\u0027);\nconst scheduleDates = computeScheduleDates(ctx.schedule, sortedItems.length);\nconst allItems = [];\n\nfor (let i = 0; i \u003c sortedItems.length; i++) {\n  const mediaItem = sortedItems[i];\n  const isPhoto = mediaItem.type === \u0027photo\u0027;\n  const override = (ctx.schedule.overrides || []).find(o =\u003e o.file === mediaItem.file) || {};\n\n  const dir = isPhoto ? ctx.photos_dir : ctx.videos_dir;\n  // v16: Use _db_path for upload batches, otherwise construct from dir\n  const filePath = mediaItem._db_path || `${dir}/${mediaItem.file}`;\n  const fileHash = mediaItem._db_hash || computeFileHash(filePath);\n\n  const date = override.date || scheduleDates[i] || ctx.schedule.start_date;\n  const slot = override.slot || ctx.schedule.slot || \u0027feed\u0027;\n  const time = override.time || (slot === \u0027story\u0027 ? ctx.schedule.defaults.story_time : ctx.schedule.defaults.feed_time);\n\n  let platforms = override.platforms;\n  if (!platforms) {\n    const platConfig = ctx.schedule.platforms || ctx.platform_defaults;\n    platforms = isPhoto ? platConfig.photos?.[slot] : platConfig.videos?.[slot];\n  }\n  platforms = (platforms || \u0027ig\u0027).toLowerCase().replace(/tiktok/g, \u0027tt\u0027).replace(/instagram/g, \u0027ig\u0027);\n\n  const contentId = generateContentId(ctx.client_slug, ctx.batch_name, date, slot, mediaItem.type, i);\n  const mediaFolder = isPhoto ? \u0027photos\u0027 : \u0027videos\u0027;\n  const cacheBuster = fileHash ? `?v=${fileHash.substring(0, 8)}` : `?t=${Date.now()}`;\n  const mediaUrl = `${ctx.media_base_url}/${mediaFolder}/${mediaItem.file}${cacheBuster}`;\n\n  const item = {\n    content_id: contentId,\n    client_slug: ctx.client_slug,\n    batch_name: ctx.batch_name,\n    media_type: mediaItem.type,\n    file_name: mediaItem.file,\n    file_path: filePath,\n    media_url: mediaUrl,\n    file_hash: fileHash,\n    file_size: mediaItem._db_size || (fs.existsSync(filePath) ? fs.statSync(filePath).size : 0),\n    file_id: mediaItem._file_id || null,\n    frames_used: isPhoto ? \u0027\u0027 : (mediaItem.frames || []).filter(f =\u003e f !== null).join(\u0027;\u0027),\n    cover_path: isPhoto ? \u0027\u0027 : (mediaItem.cover || \u0027\u0027),\n    story_path: mediaItem.story || \u0027\u0027,\n    scheduled_date: date,\n    scheduled_time: time,\n    schedule_at: `${date}T${time}:00`,\n    timezone: ctx.schedule.timezone || ctx.timezone,\n    slot,\n    platforms,\n    caption_override: override.caption_override || \u0027\u0027,\n    caption_ig: \u0027\u0027,\n    caption_tt: \u0027\u0027,\n    hashtags_final: ctx.hashtags_joined,\n    notes: override.notes || \u0027\u0027,\n    status: \u0027PENDING\u0027,\n    error_message: \u0027\u0027,\n    retry_count: 0,\n    late_media_id: \u0027\u0027,\n    late_media_url: \u0027\u0027,\n    late_post_id: \u0027\u0027,\n    instagram_account_id: ctx.instagram_account_id,\n    tiktok_account_id: ctx.tiktok_account_id,\n    fingerprint: \u0027\u0027,\n    preview_url: mediaUrl,\n    ingest_id: ctx._ingest_id,\n    image_description: \u0027\u0027,\n    description_generated_at: null,\n    _ctx: ctx,\n    _frames: isPhoto ? [] : mediaItem.frames,\n    _cover: isPhoto ? null : mediaItem.cover,\n    _deprecation_warnings: deprecationWarnings,\n    _item_index: i + 1,\n    _total_items: sortedItems.length\n  };\n\n  const fpData = `${item.client_slug}|${item.batch_name}|${item.content_id}|${item.schedule_at}|${item.platforms}|${item.file_hash}`;\n  item.fingerprint = crypto.createHash(\u0027sha256\u0027).update(fpData).digest(\u0027hex\u0027).substring(0, 16);\n  allItems.push(item);\n}\n\nconsole.log(`[W1] âœ“ Built ${allItems.length} items`);\nif (scheduleDates.length \u003e 0) {\n  console.log(`[W1] â„¹ Date range: ${scheduleDates[0]} to ${scheduleDates[scheduleDates.length - 1]}`);\n} else {\n  console.log(`[W1] â„¹ Using start_date fallback: ${ctx.schedule.start_date}`);\n}\n\n// v15.2: Initialize ingest progress tracking\ntry {\n  const Database = require(\u0027better-sqlite3\u0027);\n  const db = new Database(ctx.db_path);\n  const clientRow = db.prepare(\u0027SELECT id FROM clients WHERE slug = ?\u0027).get(ctx.client_slug);\n  if (clientRow) {\n    const progress = JSON.stringify({\n      current: 0,\n      total: allItems.length,\n      stage: \u0027discovering\u0027,\n      started_at: new Date().toISOString()\n    });\n    db.prepare(\u0027UPDATE batches SET ingest_progress = ?, ingest_started_at = datetime(\\\u0027now\\\u0027) WHERE client_id = ? AND slug = ?\u0027)\n      .run(progress, clientRow.id, ctx.batch_name);\n    console.log(\u0027[W1] âœ“ Ingest progress initialized\u0027);\n  }\n  db.close();\n} catch (e) {\n  console.log(`[W1] âš  Could not initialize progress: ${e.message}`);\n}\n\nreturn allItems.map(item =\u003e ({ json: item }));"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       480,
                                       0
                                   ],
                      "id":  "0e7d3373-00e2-4f29-a9c5-dc970d1fe77f",
                      "name":  "Auto-Discover \u0026 Schedule"
                  },
                  {
                      "parameters":  {
                                         "mode":  "runOnceForEachItem",
                                         "jsCode":  "/**\n * W1 v16: Validate Media\n * Validates each media item (file existence, frames, etc.)\n * Added progress tracking\n */\nconst fs = require(\u0027fs\u0027);\nconst crypto = require(\u0027crypto\u0027);\nconst item = $json;\n\nif (item._error) {\n  return { json: item };\n}\n\n// Update progress to validating stage\ntry {\n  const Database = require(\u0027better-sqlite3\u0027);\n  const db = new Database(item._ctx.db_path);\n  const clientRow = db.prepare(\u0027SELECT id FROM clients WHERE slug = ?\u0027).get(item.client_slug);\n  if (clientRow) {\n    const progress = JSON.stringify({\n      current: item._item_index,\n      total: item._total_items,\n      stage: \u0027validating\u0027,\n      file_name: item.file_name,\n      started_at: new Date().toISOString()\n    });\n    db.prepare(\u0027UPDATE batches SET ingest_progress = ? WHERE client_id = ? AND slug = ?\u0027)\n      .run(progress, clientRow.id, item.batch_name);\n  }\n  db.close();\n} catch (e) {\n  // Progress update failure shouldn\u0027t block validation\n}\n\nconst policy = item._ctx.policy;\nconst errors = [];\nconst warnings = [];\nconst itemErrors = [];\nlet status = \u0027NEEDS_AI\u0027;\n\n// File exists check\ntry {\n  if (!fs.existsSync(item.file_path)) {\n    errors.push(`File not found: ${item.file_name}`);\n    itemErrors.push({ code: \u0027MEDIA_NOT_FOUND\u0027, message: `File not found: ${item.file_name}` });\n  } else {\n    const buffer = fs.readFileSync(item.file_path);\n    const currentHash = crypto.createHash(\u0027md5\u0027).update(buffer).digest(\u0027hex\u0027);\n    if (item.file_hash \u0026\u0026 currentHash !== item.file_hash) {\n      warnings.push(\u0027File hash changed during processing\u0027);\n      item.file_hash = currentHash;\n      const baseUrl = item.media_url.split(\u0027?\u0027)[0];\n      item.media_url = `${baseUrl}?v=${currentHash.substring(0, 8)}`;\n      item.preview_url = item.media_url;\n    }\n  }\n} catch (e) {\n  errors.push(`Cannot access file: ${item.file_name} - ${e.message}`);\n  itemErrors.push({ code: \u0027MEDIA_NOT_FOUND\u0027, message: `Cannot access: ${e.message}` });\n}\n\n// Date validation\nif (!item.scheduled_date || !/^\\d{4}-\\d{2}-\\d{2}$/.test(item.scheduled_date)) {\n  errors.push(`Invalid date format: ${item.scheduled_date || \u0027empty\u0027}`);\n  itemErrors.push({ code: \u0027CONFIG_MISSING\u0027, message: `Invalid date: ${item.scheduled_date}` });\n}\n\n// Story slot validation\nif (policy.story_requires_story_asset \u0026\u0026 item.slot === \u0027story\u0027 \u0026\u0026 !item.story_path) {\n  warnings.push(\u0027Story slot but no _STORY variant found\u0027);\n}\n\n// TikTok requires video\nif (policy.tiktok_video_only \u0026\u0026 item.platforms.includes(\u0027tt\u0027) \u0026\u0026 item.media_type === \u0027photo\u0027) {\n  errors.push(\u0027TikTok requires video content\u0027);\n  itemErrors.push({ code: \u0027CONFIG_MISSING\u0027, message: \u0027TikTok requires video, not photo\u0027 });\n}\n\n// Video frames validation\nif (item.media_type === \u0027video\u0027 \u0026\u0026 policy.require_video_frames) {\n  const frames = item._frames || [];\n  const foundCount = frames.filter(f =\u003e f !== null).length;\n  const required = policy.video_frames_required || 4;\n\n  if (foundCount \u003c required) {\n    const missingFrames = [];\n    for (let i = 0; i \u003c required; i++) {\n      if (!frames[i]) missingFrames.push(`_F${i + 1}`);\n    }\n    const msg = `Missing video frames: ${foundCount}/${required}. Need: ${missingFrames.join(\u0027, \u0027)}`;\n    errors.push(msg);\n    itemErrors.push({ code: \u0027FRAMES_MISSING\u0027, message: msg });\n    console.log(`[W1] âœ— [FRAMES_MISSING] ${item.file_name}: ${missingFrames.join(\u0027, \u0027)}`);\n  }\n}\n\n// Cover image check\nif (item.media_type === \u0027video\u0027 \u0026\u0026 policy.require_cover_image \u0026\u0026 !item._cover) {\n  warnings.push(\u0027No cover image found\u0027);\n  itemErrors.push({ code: \u0027COVER_MISSING\u0027, message: \u0027No _COVER image found\u0027 });\n}\n\n// File size check\nif (item.file_size \u003e 0) {\n  const sizeMB = item.file_size / (1024 * 1024);\n  if (item.media_type === \u0027photo\u0027 \u0026\u0026 sizeMB \u003e 8) warnings.push(`Large photo file (${sizeMB.toFixed(1)}MB)`);\n  if (item.media_type === \u0027video\u0027 \u0026\u0026 sizeMB \u003e 500) warnings.push(`Very large video file (${sizeMB.toFixed(1)}MB)`);\n}\n\n// Caption override check\nif (item.caption_override \u0026\u0026 item.caption_override.trim() !== \u0027\u0027) {\n  status = \u0027NEEDS_REVIEW\u0027;\n}\n\n// Set final status\nif (errors.length \u003e 0) status = \u0027BLOCKED\u0027;\n\nconst allMessages = [...errors];\nif (warnings.length \u003e 0) allMessages.push(`WARNINGS: ${warnings.join(\u0027; \u0027)}`);\n\nreturn {\n  json: {\n    ...item,\n    status,\n    error_message: allMessages.join(\u0027; \u0027),\n    validated_at: new Date().toISOString(),\n    _item_errors: itemErrors\n  }\n};"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       720,
                                       0
                                   ],
                      "id":  "5280f3da-be9f-43e4-a2f9-39c6ad9c36e1",
                      "name":  "Validate Media"
                  },
                  {
                      "parameters":  {
                                         "mode":  "runOnceForEachItem",
                                         "jsCode":  "/**\n * W1 v16: Prepare Image for VLM\n * Loads photo as binary for resize, skips videos\n * v15.1: Output binary data for Edit Image node\n */\nconst fs = require(\u0027fs\u0027);\nconst path = require(\u0027path\u0027);\nconst item = $json;\n\n// Skip if error or already has description\nif (item._error || item.status === \u0027BLOCKED\u0027) {\n  return { json: { ...item, _skip_vlm: true } };\n}\n\n// Skip videos - they use frames which will be analyzed in W2\nif (item.media_type === \u0027video\u0027) {\n  console.log(`[W1] â„¹ Skipping VLM for video: ${item.file_name}`);\n  return { json: { ...item, _skip_vlm: true, image_description: \u0027\u0027, description_generated_at: null } };\n}\n\n// Load image as binary for photos\ntry {\n  if (!fs.existsSync(item.file_path)) {\n    console.log(`[W1] âš  Image file not found, skipping VLM: ${item.file_path}`);\n    return { json: { ...item, _skip_vlm: true, image_description: \u0027\u0027, description_generated_at: null } };\n  }\n  \n  const buffer = fs.readFileSync(item.file_path);\n  const ext = path.extname(item.file_name).toLowerCase();\n  const mimeType = ext === \u0027.png\u0027 ? \u0027image/png\u0027 : ext === \u0027.webp\u0027 ? \u0027image/webp\u0027 : \u0027image/jpeg\u0027;\n  \n  // Get original dimensions for logging\n  const fileSizeKB = Math.round(buffer.length / 1024);\n  console.log(`[W1] âœ“ Loaded image (${item._item_index}/${item._total_items}): ${item.file_name} (${fileSizeKB}KB)`);\n  \n  // Return with binary data for Edit Image node\n  return {\n    json: {\n      ...item,\n      _skip_vlm: false,\n      _vlm_url: item._ctx._ollama_url,\n      _vlm_timeout: item._ctx._description_timeout,\n      _vlm_model: item._ctx._image_describer_model,\n      _vlm_retry_count: 0,\n      _original_size_kb: fileSizeKB\n    },\n    binary: {\n      data: {\n        data: buffer.toString(\u0027base64\u0027),\n        mimeType: mimeType,\n        fileName: item.file_name\n      }\n    }\n  };\n} catch (e) {\n  console.log(`[W1] âš  Error loading image: ${e.message}`);\n  return { json: { ...item, _skip_vlm: true, image_description: \u0027\u0027, description_generated_at: null } };\n}"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       960,
                                       0
                                   ],
                      "id":  "prepare-vlm-request",
                      "name":  "Prepare Image for VLM"
                  },
                  {
                      "parameters":  {
                                         "conditions":  {
                                                            "options":  {
                                                                            "caseSensitive":  true,
                                                                            "leftValue":  "",
                                                                            "typeValidation":  "strict"
                                                                        },
                                                            "conditions":  [
                                                                               {
                                                                                   "id":  "skip-vlm-check",
                                                                                   "leftValue":  "={{ $json._skip_vlm }}",
                                                                                   "rightValue":  true,
                                                                                   "operator":  {
                                                                                                    "type":  "boolean",
                                                                                                    "operation":  "equals"
                                                                                                }
                                                                               }
                                                                           ],
                                                            "combinator":  "and"
                                                        },
                                         "options":  {

                                                     }
                                     },
                      "type":  "n8n-nodes-base.if",
                      "typeVersion":  2.2,
                      "position":  [
                                       1180,
                                       0
                                   ],
                      "id":  "should-skip-vlm",
                      "name":  "Skip VLM?"
                  },
                  {
                      "parameters":  {
                                         "operation":  "resize",
                                         "dataPropertyName":  "data",
                                         "width":  1024,
                                         "height":  1024,
                                         "resizeOption":  "onlyIfLarger",
                                         "options":  {
                                                         "format":  "jpeg",
                                                         "quality":  85
                                                     }
                                     },
                      "type":  "n8n-nodes-base.editImage",
                      "typeVersion":  1,
                      "position":  [
                                       1400,
                                       -120
                                   ],
                      "id":  "resize-for-vlm",
                      "name":  "Resize for VLM"
                  },
                  {
                      "parameters":  {
                                         "mode":  "runOnceForEachItem",
                                         "jsCode":  "/**\n * W1 v16: Build VLM Request\n * Converts resized binary image to base64 for Ollama\n * n8n Edit Image outputs binary in $binary.data with base64 in .data property\n * Added progress tracking\n * Language-specific prompts\n */\nconst item = $json;\nconst binary = $binary;\n\n// Update progress to describing stage\ntry {\n  const Database = require(\u0027better-sqlite3\u0027);\n  const db = new Database(item._ctx.db_path);\n  const clientRow = db.prepare(\u0027SELECT id FROM clients WHERE slug = ?\u0027).get(item.client_slug);\n  if (clientRow) {\n    const progress = JSON.stringify({\n      current: item._item_index,\n      total: item._total_items,\n      stage: \u0027describing\u0027,\n      file_name: item.file_name,\n      started_at: new Date().toISOString()\n    });\n    db.prepare(\u0027UPDATE batches SET ingest_progress = ? WHERE client_id = ? AND slug = ?\u0027)\n      .run(progress, clientRow.id, item.batch_name);\n  }\n  db.close();\n} catch (e) {\n  // Progress update failure shouldn\u0027t block VLM\n}\n\n// Debug: log what we received\nconsole.log(`[W1] Binary keys: ${binary ? Object.keys(binary).join(\u0027, \u0027) : \u0027null\u0027}`);\nif (binary \u0026\u0026 binary.data) {\n  console.log(`[W1] Binary.data keys: ${Object.keys(binary.data).join(\u0027, \u0027)}`);\n}\n\n// n8n binary format: $binary.data.data contains base64 string\nlet imageBase64 = \u0027\u0027;\nif (binary \u0026\u0026 binary.data) {\n  // Try different property names that n8n might use\n  imageBase64 = binary.data.data || binary.data.base64 || \u0027\u0027;\n  \n  // If still empty, try to convert from Buffer if present\n  if (!imageBase64 \u0026\u0026 binary.data.buffer) {\n    imageBase64 = Buffer.from(binary.data.buffer).toString(\u0027base64\u0027);\n  }\n}\n\nif (!imageBase64) {\n  console.log(`[W1] âš  No binary data for VLM request: ${item.content_id}`);\n  console.log(`[W1] Binary structure: ${JSON.stringify(binary, null, 2).substring(0, 500)}`);\n  return { json: { ...item, _skip_vlm: true, image_description: \u0027\u0027 } };\n}\n\nconst resizedSizeKB = Math.round(imageBase64.length * 0.75 / 1024);\nconsole.log(`[W1] âœ“ Resized for VLM: ${item.file_name} (${item._original_size_kb || \u0027?\u0027}KB â†’ ${resizedSizeKB}KB)`);\n\n// Language-specific prompts\nconst language = item._ctx?.language || \u0027fr\u0027;\nconsole.log(`[W1] â„¹ Using language: ${language}`);\n\n// Build VLM prompt in client\u0027s language\nconst prompts = {\n  fr: `USER: \u003cimage\u003e\\nDÃ©cris cette image de maniÃ¨re objective en 2-3 phrases pour un contexte de rÃ©seaux sociaux. Inclus :\\n- Le(s) sujet(s) principal(aux) et leur apparence\\n- Le cadre/environnement et l\u0027atmosphÃ¨re\\n- Les couleurs, l\u0027Ã©clairage, l\u0027ambiance ou l\u0027Ã©motion transmise\\n- Toute action ou interaction notable\\n\\nConcentre-toi sur les dÃ©tails qui inspireraient des lÃ©gendes engageantes. Sois factuel mais capture la qualitÃ© Ã©motionnelle.\\nN\u0027Ã©cris PAS de lÃ©gendes ni de texte marketing.\\n\\nRÃ©ponds en franÃ§ais.\\n\\nA:`,\n  en: `USER: \u003cimage\u003e\\nDescribe this image objectively in 2-3 sentences for social media context. Include:\\n- Main subject(s) and their appearance\\n- Setting/environment and atmosphere\\n- Colors, lighting, mood or feeling conveyed\\n- Any notable action or interaction\\n\\nFocus on details that would inspire engaging captions. Be factual but capture the emotional quality.\\nDo NOT write captions or suggest marketing text.\\n\\nA:`,\n  de: `USER: \u003cimage\u003e\\nBeschreibe dieses Bild objektiv in 2-3 SÃ¤tzen fÃ¼r einen Social-Media-Kontext. Beinhalte:\\n- Hauptmotiv(e) und deren Erscheinung\\n- Umgebung/Setting und AtmosphÃ¤re\\n- Farben, Beleuchtung, vermittelte Stimmung oder Emotion\\n- Bemerkenswerte Aktionen oder Interaktionen\\n\\nKonzentriere dich auf Details, die zu ansprechenden Bildunterschriften inspirieren. Sei sachlich, aber erfasse die emotionale QualitÃ¤t.\\nSchreibe KEINE Bildunterschriften oder Marketing-Texte.\\n\\nAntworte auf Deutsch.\\n\\nA:`\n};\n\nconst vlmPrompt = prompts[language] || prompts.fr;\n\nreturn {\n  json: {\n    ...item,\n    _vlm_request: {\n      model: item._vlm_model,\n      prompt: vlmPrompt,\n      images: [imageBase64],\n      stream: false,\n      options: {\n        temperature: 0.5,\n        num_predict: 200\n      }\n    },\n    _resized_size_kb: resizedSizeKB\n  }\n};"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       1620,
                                       -120
                                   ],
                      "id":  "build-vlm-request",
                      "name":  "Build VLM Request"
                  },
                  {
                      "parameters":  {
                                         "method":  "POST",
                                         "url":  "={{ $json._vlm_url }}",
                                         "sendBody":  true,
                                         "specifyBody":  "json",
                                         "jsonBody":  "={{ JSON.stringify($json._vlm_request) }}",
                                         "options":  {
                                                         "timeout":  "={{ $json._vlm_timeout || 60000 }}"
                                                     }
                                     },
                      "type":  "n8n-nodes-base.httpRequest",
                      "typeVersion":  4.2,
                      "position":  [
                                       1840,
                                       -120
                                   ],
                      "id":  "call-vlm",
                      "name":  "Call VLM",
                      "onError":  "continueRegularOutput"
                  },
                  {
                      "parameters":  {
                                         "mode":  "runOnceForEachItem",
                                         "jsCode":  "/**\n * W1 v16: Handle VLM Response\n * Process VLM response with retry logic\n */\nconst prevItem = $(\u0027Build VLM Request\u0027).item;\nconst response = $json;\n\nif (!prevItem || !prevItem.json) {\n  return { json: { _error: true, error_code: \u0027MISSING_DATA\u0027 } };\n}\n\nconst item = prevItem.json;\nconst config = item._ctx;\n\n// Check for errors\nif (response.error || !response.response) {\n  const errorMsg = response.error || \u0027No response from VLM\u0027;\n  console.log(`[W1] âš  VLM error for ${item.content_id}: ${errorMsg}`);\n  \n  const retryCount = item._vlm_retry_count || 0;\n  const maxRetries = config?.caption_generation?.vlm_max_retries ?? 2;\n  \n  if (retryCount \u003c maxRetries) {\n    // Queue for retry\n    console.log(`[W1] â„¹ Queuing VLM retry ${retryCount + 1}/${maxRetries} for ${item.content_id}`);\n    return { \n      json: { \n        ...item, \n        _vlm_retry_count: retryCount + 1,\n        _vlm_needs_retry: true,\n        image_description: \u0027\u0027,\n        description_generated_at: null\n      } \n    };\n  }\n  \n  // Max retries reached - continue without description\n  console.log(`[W1] âš  Max VLM retries (${maxRetries}) reached for ${item.content_id}, continuing without description`);\n  return { \n    json: { \n      ...item, \n      _vlm_needs_retry: false,\n      image_description: \u0027\u0027,\n      description_generated_at: null,\n      _vlm_error: errorMsg\n    } \n  };\n}\n\n// Parse successful response\nlet description = (response.response || \u0027\u0027).trim();\n\n// Clean up common VLM artifacts\ndescription = description\n  .replace(/^(The image shows|This image shows|I see|In this image,?)\\s*/i, \u0027\u0027)\n  .replace(/^(Here is|Here\u0027s)\\s+.*?:\\s*/i, \u0027\u0027)\n  .replace(/\\n+/g, \u0027 \u0027)\n  .trim();\n\nconsole.log(`[W1] âœ“ VLM description for ${item.content_id}: ${description.substring(0, 80)}...`);\n\nreturn {\n  json: {\n    ...item,\n    _vlm_needs_retry: false,\n    image_description: description,\n    description_generated_at: new Date().toISOString()\n  }\n};"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       2060,
                                       -120
                                   ],
                      "id":  "handle-vlm-response",
                      "name":  "Handle VLM Response"
                  },
                  {
                      "parameters":  {
                                         "conditions":  {
                                                            "options":  {
                                                                            "caseSensitive":  true,
                                                                            "leftValue":  "",
                                                                            "typeValidation":  "strict"
                                                                        },
                                                            "conditions":  [
                                                                               {
                                                                                   "id":  "needs-retry-check",
                                                                                   "leftValue":  "={{ $json._vlm_needs_retry }}",
                                                                                   "rightValue":  true,
                                                                                   "operator":  {
                                                                                                    "type":  "boolean",
                                                                                                    "operation":  "equals"
                                                                                                }
                                                                               }
                                                                           ],
                                                            "combinator":  "and"
                                                        },
                                         "options":  {

                                                     }
                                     },
                      "type":  "n8n-nodes-base.if",
                      "typeVersion":  2.2,
                      "position":  [
                                       2280,
                                       -120
                                   ],
                      "id":  "needs-vlm-retry",
                      "name":  "Needs Retry?"
                  },
                  {
                      "parameters":  {
                                         "mode":  "runOnceForEachItem",
                                         "jsCode":  "/**\n * W1 v16: Prepare VLM Retry\n * Rebuild request for retry with resized image\n * Language-specific prompts\n */\nconst fs = require(\u0027fs\u0027);\nconst item = $json;\n\nconsole.log(`[W1] â„¹ Retrying VLM for ${item.content_id}`);\n\n// Reload and resize image\nlet imageBase64 = \u0027\u0027;\ntry {\n  if (fs.existsSync(item.file_path)) {\n    const buffer = fs.readFileSync(item.file_path);\n    // Note: For retry we use original - resize happens in main path\n    // This is a simplified retry that just reloads the original\n    imageBase64 = buffer.toString(\u0027base64\u0027);\n  }\n} catch (e) {\n  console.log(`[W1] âš  Error reloading image for retry: ${e.message}`);\n  return { json: { ...item, _vlm_needs_retry: false, image_description: \u0027\u0027 } };\n}\n\n// Language-specific prompts\nconst language = item._ctx?.language || \u0027fr\u0027;\nconst prompts = {\n  fr: `USER: \u003cimage\u003e\\nDÃ©cris cette image de maniÃ¨re objective en 2-3 phrases pour un contexte de rÃ©seaux sociaux. Inclus :\\n- Le(s) sujet(s) principal(aux) et leur apparence\\n- Le cadre/environnement et l\u0027atmosphÃ¨re\\n- Les couleurs, l\u0027Ã©clairage, l\u0027ambiance ou l\u0027Ã©motion transmise\\n- Toute action ou interaction notable\\n\\nConcentre-toi sur les dÃ©tails qui inspireraient des lÃ©gendes engageantes. Sois factuel mais capture la qualitÃ© Ã©motionnelle.\\nN\u0027Ã©cris PAS de lÃ©gendes ni de texte marketing.\\n\\nRÃ©ponds en franÃ§ais.\\n\\nA:`,\n  en: `USER: \u003cimage\u003e\\nDescribe this image objectively in 2-3 sentences for social media context. Include:\\n- Main subject(s) and their appearance\\n- Setting/environment and atmosphere\\n- Colors, lighting, mood or feeling conveyed\\n- Any notable action or interaction\\n\\nFocus on details that would inspire engaging captions. Be factual but capture the emotional quality.\\nDo NOT write captions or suggest marketing text.\\n\\nA:`,\n  de: `USER: \u003cimage\u003e\\nBeschreibe dieses Bild objektiv in 2-3 SÃ¤tzen fÃ¼r einen Social-Media-Kontext. Beinhalte:\\n- Hauptmotiv(e) und deren Erscheinung\\n- Umgebung/Setting und AtmosphÃ¤re\\n- Farben, Beleuchtung, vermittelte Stimmung oder Emotion\\n- Bemerkenswerte Aktionen oder Interaktionen\\n\\nKonzentriere dich auf Details, die zu ansprechenden Bildunterschriften inspirieren. Sei sachlich, aber erfasse die emotionale QualitÃ¤t.\\nSchreibe KEINE Bildunterschriften oder Marketing-Texte.\\n\\nAntworte auf Deutsch.\\n\\nA:`\n};\nconst vlmPrompt = prompts[language] || prompts.fr;\n\nreturn {\n  json: {\n    ...item,\n    _vlm_request: {\n      model: item._vlm_model,\n      prompt: vlmPrompt,\n      images: [imageBase64],\n      stream: false,\n      options: { temperature: 0.5, num_predict: 200 }\n    }\n  }\n};"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       2500,
                                       -240
                                   ],
                      "id":  "prepare-vlm-retry",
                      "name":  "Prepare VLM Retry"
                  },
                  {
                      "parameters":  {
                                         "mode":  "append"
                                     },
                      "type":  "n8n-nodes-base.merge",
                      "typeVersion":  3.1,
                      "position":  [
                                       2720,
                                       0
                                   ],
                      "id":  "merge-vlm-results",
                      "name":  "Merge VLM Results"
                  },
                  {
                      "parameters":  {
                                         "mode":  "runOnceForEachItem",
                                         "jsCode":  "/**\n * W1 v16: Clean Item for DB\n * Remove internal fields before database insert\n */\nconst item = $json;\n\n// Remove internal VLM fields but keep image_description\nconst { \n  _ctx, _frames, _cover, _deprecation_warnings, \n  _vlm_request, _vlm_url, _vlm_timeout, _vlm_retry_count, _vlm_needs_retry, _vlm_error,\n  _vlm_model, _original_size_kb, _resized_size_kb,\n  _skip_vlm,\n  ...cleanItem \n} = item;\n\nreturn {\n  json: {\n    ...cleanItem,\n    _db_path: _ctx?.db_path || item._db_path,\n    _client_config: _ctx?.client_config || item._client_config,\n    _batch_config: _ctx?.batch_config || item._batch_config\n  }\n};"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       2940,
                                       0
                                   ],
                      "id":  "clean-for-db",
                      "name":  "Clean for DB"
                  },
                  {
                      "parameters":  {
                                         "jsCode":  "/**\n * W1 v16: Upsert to SQLite\n * Creates/updates client, batch, and content item records\n * v15: Added image_description and description_generated_at fields\n */\nconst Database = require(\u0027better-sqlite3\u0027);\nconst items = $input.all();\n\nif (items.length === 1 \u0026\u0026 items[0].json._error) {\n  return items;\n}\n\nif (items.length === 0) {\n  throw new Error(\u0027No items to insert\u0027);\n}\n\nconst firstItem = items[0].json;\nconst dbPath = firstItem._db_path;\nconst clientConfig = firstItem._client_config;\nconst batchConfig = firstItem._batch_config;\n\nconsole.log(`[W1] â„¹ Opening database: ${dbPath}`);\nlet db = null;\n\ntry {\n  db = new Database(dbPath);\n  db.pragma(\u0027foreign_keys = ON\u0027);\n\n  // Upsert client\n  const upsertClient = db.prepare(`\n    INSERT INTO clients (slug, name, is_active, language, timezone, brand_voice, brand_target_audience, brand_description, hashtags, platform_defaults, policy)\n    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n    ON CONFLICT(slug) DO UPDATE SET\n      name = excluded.name, is_active = excluded.is_active, language = excluded.language, timezone = excluded.timezone,\n      brand_voice = excluded.brand_voice, brand_target_audience = excluded.brand_target_audience, brand_description = excluded.brand_description,\n      hashtags = excluded.hashtags, platform_defaults = excluded.platform_defaults, policy = excluded.policy\n  `);\n\n  upsertClient.run(\n    firstItem.client_slug,\n    clientConfig.name || firstItem.client_slug,\n    clientConfig.is_active !== false ? 1 : 0,\n    clientConfig.language || \u0027fr\u0027,\n    clientConfig.timezone || \u0027Europe/Berlin\u0027,\n    clientConfig.brand?.voice || null,\n    clientConfig.brand?.target_audience || null,\n    clientConfig.brand?.description || null,\n    JSON.stringify(clientConfig.hashtags || []),\n    JSON.stringify(clientConfig.platform_defaults || {}),\n    JSON.stringify(clientConfig.policy || {})\n  );\n\n  const clientRow = db.prepare(\u0027SELECT id FROM clients WHERE slug = ?\u0027).get(firstItem.client_slug);\n  const clientId = clientRow.id;\n  console.log(`[W1] âœ“ Client upserted: ${firstItem.client_slug} (id=${clientId})`);\n\n  // Upsert accounts\n  const upsertAccount = db.prepare(`\n    INSERT INTO accounts (client_id, platform, late_account_id, username, is_default, is_active)\n    VALUES (?, ?, ?, ?, ?, 1)\n    ON CONFLICT(client_id, platform, late_account_id) DO UPDATE SET username = excluded.username, is_default = excluded.is_default\n  `);\n\n  function insertAccounts(platform, accountsConfig) {\n    if (!accountsConfig) return;\n    const accounts = Array.isArray(accountsConfig) ? accountsConfig : [accountsConfig];\n    for (const acc of accounts) {\n      if (acc.late_account_id) {\n        upsertAccount.run(clientId, platform, acc.late_account_id, acc.username || null, acc.is_default ? 1 : 0);\n        console.log(`[W1] âœ“ Account upserted: ${platform} - ${acc.username || acc.late_account_id}`);\n      }\n    }\n  }\n\n  insertAccounts(\u0027instagram\u0027, clientConfig.accounts?.instagram);\n  insertAccounts(\u0027tiktok\u0027, clientConfig.accounts?.tiktok);\n\n  // Upsert batch\n  const upsertBatch = db.prepare(`\n    INSERT INTO batches (client_id, slug, name, description, brief, hashtags, schedule_config, folder_path, status)\n    VALUES (?, ?, ?, ?, ?, ?, ?, ?, \u0027processing\u0027)\n    ON CONFLICT(client_id, slug) DO UPDATE SET\n      name = excluded.name, description = excluded.description, brief = excluded.brief, hashtags = excluded.hashtags,\n      schedule_config = excluded.schedule_config, folder_path = excluded.folder_path, status = \u0027processing\u0027\n  `);\n\n  const batchFolder = firstItem.file_path.split(\u0027/\u0027).slice(0, -2).join(\u0027/\u0027);\n\n  upsertBatch.run(\n    clientId,\n    firstItem.batch_name,\n    batchConfig.name || firstItem.batch_name,\n    batchConfig.description || null,\n    batchConfig.brief || null,\n    JSON.stringify(batchConfig.hashtags || []),\n    JSON.stringify(batchConfig.schedule || {}),\n    batchFolder\n  );\n\n  const batchRow = db.prepare(\u0027SELECT id FROM batches WHERE client_id = ? AND slug = ?\u0027).get(clientId, firstItem.batch_name);\n  const batchId = batchRow.id;\n  console.log(`[W1] âœ“ Batch upserted: ${firstItem.batch_name} (id=${batchId})`);\n\n  // Upsert content items (v15: added image_description, description_generated_at)\n  const upsertItem = db.prepare(`\n    INSERT INTO content_items (\n      content_id, client_id, batch_id, media_type, file_name, file_path, file_hash, file_size, media_url, preview_url,\n      frames_used, cover_path, story_path, scheduled_date, scheduled_time, schedule_at, timezone, slot, platforms,\n      image_description, description_generated_at,\n      caption_ig, caption_tt, caption_override, hashtags_final, status, error_message, retry_count,\n      late_media_id, late_media_url, late_post_id, instagram_account_id, tiktok_account_id, notes, fingerprint, ingest_id, validated_at\n    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n    ON CONFLICT(content_id) DO UPDATE SET\n      file_hash = excluded.file_hash, file_size = excluded.file_size, media_url = excluded.media_url, preview_url = excluded.preview_url,\n      frames_used = excluded.frames_used, cover_path = excluded.cover_path, story_path = excluded.story_path,\n      scheduled_date = excluded.scheduled_date, scheduled_time = excluded.scheduled_time, schedule_at = excluded.schedule_at,\n      platforms = excluded.platforms, hashtags_final = excluded.hashtags_final,\n      image_description = COALESCE(excluded.image_description, content_items.image_description),\n      description_generated_at = COALESCE(excluded.description_generated_at, content_items.description_generated_at),\n      status = CASE WHEN content_items.status IN (\u0027SCHEDULED\u0027, \u0027PUBLISHED\u0027) THEN content_items.status ELSE excluded.status END,\n      error_message = excluded.error_message, fingerprint = excluded.fingerprint, ingest_id = excluded.ingest_id, validated_at = excluded.validated_at\n  `);\n\n  let insertedCount = 0;\n  let updatedCount = 0;\n  let descriptionsGenerated = 0;\n\n  const insertMany = db.transaction((items) =\u003e {\n    for (const item of items) {\n      const d = item.json;\n      const existing = db.prepare(\u0027SELECT id FROM content_items WHERE content_id = ?\u0027).get(d.content_id);\n\n      upsertItem.run(\n        d.content_id, clientId, batchId, d.media_type, d.file_name, d.file_path, d.file_hash || null, d.file_size || 0,\n        d.media_url || null, d.preview_url || null, d.frames_used || null, d.cover_path || null, d.story_path || null,\n        d.scheduled_date, d.scheduled_time, d.schedule_at, d.timezone || \u0027Europe/Berlin\u0027, d.slot || \u0027feed\u0027, d.platforms || \u0027ig\u0027,\n        d.image_description || null, d.description_generated_at || null,\n        d.caption_ig || null, d.caption_tt || null, d.caption_override || null, d.hashtags_final || null,\n        d.status || \u0027PENDING\u0027, d.error_message || null, d.retry_count || 0,\n        d.late_media_id || null, d.late_media_url || null, d.late_post_id || null,\n        d.instagram_account_id || null, d.tiktok_account_id || null, d.notes || null, d.fingerprint || null, d.ingest_id || null, d.validated_at || null\n      );\n\n      if (existing) updatedCount++;\n      else insertedCount++;\n      \n      if (d.image_description \u0026\u0026 d.image_description.length \u003e 0) descriptionsGenerated++;\n    }\n  });\n\n  insertMany(items);\n  console.log(`[W1] âœ“ Content items: ${insertedCount} inserted, ${updatedCount} updated`);\n  console.log(`[W1] âœ“ Image descriptions: ${descriptionsGenerated} generated`);\n\n  // Audit log\n  const insertAudit = db.prepare(`INSERT INTO audit_log (entity_type, entity_id, action, new_value) VALUES (\u0027batch\u0027, ?, \u0027ingest\u0027, ?)`);\n  insertAudit.run(batchId, JSON.stringify({ \n    ingest_id: firstItem.ingest_id, \n    items_inserted: insertedCount, \n    items_updated: updatedCount, \n    total_items: items.length,\n    descriptions_generated: descriptionsGenerated\n  }));\n  console.log(\u0027[W1] âœ“ Audit log entry created\u0027);\n\n} finally {\n  if (db) db.close();\n}\n\nreturn items.map(item =\u003e {\n  const { _db_path, _client_config, _batch_config, ...clean } = item.json;\n  return { json: clean };\n});"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       3160,
                                       0
                                   ],
                      "id":  "9a5807fc-7141-4489-9631-f1584e3e6d5a",
                      "name":  "Upsert to SQLite"
                  },
                  {
                      "parameters":  {
                                         "jsCode":  "/**\n * W1 v16: Batch Report\n * Generates final ingest report and writes job status\n * v15.2: Added progress cleanup\n */\nconst fs = require(\u0027fs\u0027);\nconst items = $input.all();\n\n// Handle early error exit\nif (items.length === 1 \u0026\u0026 items[0].json._error) {\n  const data = items[0].json;\n  const duration = ((Date.now() - data._start_time) / 1000).toFixed(1);\n\n  // Write job status (failed)\n  const jobPath = `${data._config_base}/active_job.json`;\n  try {\n    let jobs = { current: {}, executions: {} };\n    if (fs.existsSync(jobPath)) jobs = JSON.parse(fs.readFileSync(jobPath, \u0027utf8\u0027));\n    jobs.executions = jobs.executions || {};\n    jobs.executions.W1 = {\n      last_run: new Date().toISOString(),\n      status: \u0027failed\u0027,\n      client: data.client || null,\n      batch: data.batch || null,\n      duration_ms: Date.now() - data._start_time,\n      error_code: data.error_code,\n      error_message: data.error_message\n    };\n    fs.writeFileSync(jobPath, JSON.stringify(jobs, null, 2));\n    console.log(\u0027[W1] âœ“ Job status written (failed)\u0027);\n  } catch (e) {\n    console.log(`[W1] âš  Could not write job status: ${e.message}`);\n  }\n\n  console.log(\u0027[W1] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u0027);\n  console.log(`[W1] âœ— FAILED: ${data.error_code}`);\n  console.log(`[W1]   ${data.error_message}`);\n  console.log(\u0027[W1] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u0027);\n\n  return [{\n    json: {\n      success: false,\n      workflow: \u0027W1\u0027,\n      version: \u002716\u0027,\n      error_code: data.error_code,\n      error_message: data.error_message,\n      client: data.client || null,\n      batch: data.batch || null,\n      duration_seconds: parseFloat(duration),\n      generated_at: new Date().toISOString()\n    }\n  }];\n}\n\nconst configNode = $(\u0027Load Config (YAML)\u0027).first().json;\nconst startTime = configNode._start_time || Date.now();\nconst duration = ((Date.now() - startTime) / 1000).toFixed(1);\n\n// Collect per-item errors and stats\nconst itemErrors = [];\nlet descriptionsGenerated = 0;\nfor (const item of items) {\n  if (item.json._item_errors?.length \u003e 0) {\n    for (const err of item.json._item_errors) {\n      itemErrors.push({ content_id: item.json.content_id, file: item.json.file_name, code: err.code, message: err.message });\n    }\n  }\n  if (item.json.image_description \u0026\u0026 item.json.image_description.length \u003e 0) {\n    descriptionsGenerated++;\n  }\n}\n\nconst blockedCount = items.filter(i =\u003e i.json.status === \u0027BLOCKED\u0027).length;\nconst hasErrors = blockedCount \u003e 0;\n\nconst report = {\n  success: !hasErrors,\n  workflow: \u0027W1\u0027,\n  version: \u002716\u0027,\n  generated_at: new Date().toISOString(),\n  duration_seconds: parseFloat(duration),\n  client: configNode.client_slug || \u0027unknown\u0027,\n  batch: configNode.batch_name || \u0027unknown\u0027,\n  source: configNode._source || \u0027unknown\u0027,\n  ingest_id: configNode._ingest_id,\n  ...(hasErrors \u0026\u0026 { error_code: \u0027VALIDATION_FAILED\u0027, error_message: `${blockedCount} items blocked` }),\n  summary: {\n    total: items.length,\n    ready_for_ai: items.filter(i =\u003e i.json.status === \u0027NEEDS_AI\u0027).length,\n    ready_for_review: items.filter(i =\u003e i.json.status === \u0027NEEDS_REVIEW\u0027).length,\n    blocked: blockedCount,\n    image_descriptions: descriptionsGenerated\n  },\n  by_type: {\n    photos: items.filter(i =\u003e i.json.media_type === \u0027photo\u0027).length,\n    videos: items.filter(i =\u003e i.json.media_type === \u0027video\u0027).length\n  },\n  schedule_info: {\n    start_date: items.length \u003e 0 ? items[0].json.scheduled_date : null,\n    end_date: items.length \u003e 0 ? items[items.length - 1].json.scheduled_date : null,\n    total_days: items.length \u003e 0 ? Math.ceil((new Date(items[items.length - 1].json.scheduled_date) - new Date(items[0].json.scheduled_date)) / (1000 * 60 * 60 * 24)) + 1 : 0\n  },\n  optimization: {\n    vlm_resize_enabled: configNode._vlm_resize_enabled,\n    vlm_resize_max: configNode._vlm_resize_max,\n    vlm_resize_quality: configNode._vlm_resize_quality\n  },\n  errors: itemErrors,\n  blocked_items: items.filter(i =\u003e i.json.status === \u0027BLOCKED\u0027).map(i =\u003e ({ content_id: i.json.content_id, file: i.json.file_name, error: i.json.error_message })),\n  next_steps: []\n};\n\nif (report.summary.blocked \u003e 0) report.next_steps.push(`Fix ${report.summary.blocked} blocked items`);\nif (report.summary.ready_for_ai \u003e 0) report.next_steps.push(`Run W2 to generate AI captions for ${report.summary.ready_for_ai} items`);\nif (report.summary.ready_for_review \u003e 0) report.next_steps.push(`${report.summary.ready_for_review} items have manual captions - review in UI`);\n\n// Write job status\nconst jobPath = `${configNode._config_base}/active_job.json`;\ntry {\n  let jobs = { current: {}, executions: {} };\n  if (fs.existsSync(jobPath)) jobs = JSON.parse(fs.readFileSync(jobPath, \u0027utf8\u0027));\n  jobs.executions = jobs.executions || {};\n  jobs.executions.W1 = {\n    last_run: new Date().toISOString(),\n    status: hasErrors ? \u0027partial\u0027 : \u0027success\u0027,\n    client: report.client,\n    batch: report.batch,\n    ingest_id: report.ingest_id,\n    duration_ms: Date.now() - startTime,\n    summary: report.summary,\n    ...(itemErrors.length \u003e 0 \u0026\u0026 { errors: itemErrors })\n  };\n  fs.writeFileSync(jobPath, JSON.stringify(jobs, null, 2));\n  console.log(\u0027[W1] âœ“ Job status written\u0027);\n} catch (e) {\n  console.log(`[W1] âš  Could not write job status: ${e.message}`);\n}\n\n// v15.2: Clear ingest progress\ntry {\n  const Database = require(\u0027better-sqlite3\u0027);\n  const db = new Database(configNode.db_path);\n  const clientRow = db.prepare(\u0027SELECT id FROM clients WHERE slug = ?\u0027).get(configNode.client_slug);\n  if (clientRow) {\n    db.prepare(\u0027UPDATE batches SET ingest_progress = NULL WHERE client_id = ? AND slug = ?\u0027)\n      .run(clientRow.id, configNode.batch_name);\n    console.log(\u0027[W1] âœ“ Ingest progress cleared\u0027);\n  }\n  db.close();\n} catch (e) {\n  console.log(`[W1] âš  Could not clear progress: ${e.message}`);\n}\n\nconsole.log(\u0027[W1] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u0027);\nconsole.log(`[W1] ${hasErrors ? \u0027âš \u0027 : \u0027âœ“\u0027} Ingest complete: ${report.summary.total} items`);\nconsole.log(`[W1]   Ready for AI: ${report.summary.ready_for_ai}`);\nconsole.log(`[W1]   Ready for review: ${report.summary.ready_for_review}`);\nconsole.log(`[W1]   Blocked: ${report.summary.blocked}`);\nconsole.log(`[W1]   Image descriptions: ${report.summary.image_descriptions}`);\nconsole.log(\u0027[W1] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u0027);\n\nreturn [{ json: report }];"
                                     },
                      "type":  "n8n-nodes-base.code",
                      "typeVersion":  2,
                      "position":  [
                                       3380,
                                       0
                                   ],
                      "id":  "7c3bd6a9-e08f-412d-bd0c-4b2eac1b75d4",
                      "name":  "Batch Report"
                  },
                  {
                      "parameters":  {
                                         "respondWith":  "json",
                                         "responseBody":  "={{ $json }}",
                                         "options":  {

                                                     }
                                     },
                      "type":  "n8n-nodes-base.respondToWebhook",
                      "typeVersion":  1.5,
                      "position":  [
                                       3600,
                                       112
                                   ],
                      "id":  "756ff6b9-52b6-4207-88fc-aa46ee381eaa",
                      "name":  "Webhook Response"
                  },
                  {
                      "parameters":  {
                                         "method":  "POST",
                                         "url":  "=http://localhost:5678/webhook/w2-captions",
                                         "sendBody":  true,
                                         "specifyBody":  "json",
                                         "jsonBody":  "={{ JSON.stringify({ client: $json.client, batch: $json.batch, auto_triggered: true }) }}",
                                         "options":  {
                                                         "timeout":  5000,
                                                         "allowUnauthorizedCerts":  true
                                                     }
                                     },
                      "type":  "n8n-nodes-base.httpRequest",
                      "typeVersion":  4.3,
                      "position":  [
                                       3600,
                                       -112
                                   ],
                      "id":  "trigger-w2-auto",
                      "name":  "Trigger W2 Captions",
                      "onError":  "continueRegularOutput",
                      "executeOnce":  true
                  },
                  {
                      "parameters":  {
                                         "conditions":  {
                                                            "options":  {
                                                                            "caseSensitive":  true,
                                                                            "leftValue":  "",
                                                                            "typeValidation":  "strict"
                                                                        },
                                                            "conditions":  [
                                                                               {
                                                                                   "id":  "check-ready-for-ai",
                                                                                   "leftValue":  "={{ $json.summary?.ready_for_ai }}",
                                                                                   "rightValue":  0,
                                                                                   "operator":  {
                                                                                                    "type":  "number",
                                                                                                    "operation":  "gt"
                                                                                                }
                                                                               }
                                                                           ],
                                                            "combinator":  "and"
                                                        }
                                     },
                      "type":  "n8n-nodes-base.if",
                      "typeVersion":  2,
                      "position":  [
                                       3380,
                                       -112
                                   ],
                      "id":  "check-trigger-w2",
                      "name":  "Has Items for AI?"
                  }
              ],
    "connections":  {
                        "Webhook Trigger":  {
                                                "main":  [
                                                             [
                                                                 {
                                                                     "node":  "Load Config (YAML)",
                                                                     "type":  "main",
                                                                     "index":  0
                                                                 }
                                                             ]
                                                         ]
                                            },
                        "Load Config (YAML)":  {
                                                   "main":  [
                                                                [
                                                                    {
                                                                        "node":  "Validate Context",
                                                                        "type":  "main",
                                                                        "index":  0
                                                                    }
                                                                ]
                                                            ]
                                               },
                        "Validate Context":  {
                                                 "main":  [
                                                              [
                                                                  {
                                                                      "node":  "Auto-Discover \u0026 Schedule",
                                                                      "type":  "main",
                                                                      "index":  0
                                                                  }
                                                              ]
                                                          ]
                                             },
                        "Auto-Discover \u0026 Schedule":  {
                                                              "main":  [
                                                                           [
                                                                               {
                                                                                   "node":  "Validate Media",
                                                                                   "type":  "main",
                                                                                   "index":  0
                                                                               }
                                                                           ]
                                                                       ]
                                                          },
                        "Validate Media":  {
                                               "main":  [
                                                            [
                                                                {
                                                                    "node":  "Prepare Image for VLM",
                                                                    "type":  "main",
                                                                    "index":  0
                                                                }
                                                            ]
                                                        ]
                                           },
                        "Prepare Image for VLM":  {
                                                      "main":  [
                                                                   [
                                                                       {
                                                                           "node":  "Skip VLM?",
                                                                           "type":  "main",
                                                                           "index":  0
                                                                       }
                                                                   ]
                                                               ]
                                                  },
                        "Skip VLM?":  {
                                          "main":  [
                                                       [
                                                           {
                                                               "node":  "Merge VLM Results",
                                                               "type":  "main",
                                                               "index":  0
                                                           }
                                                       ],
                                                       [
                                                           {
                                                               "node":  "Resize for VLM",
                                                               "type":  "main",
                                                               "index":  0
                                                           }
                                                       ]
                                                   ]
                                      },
                        "Resize for VLM":  {
                                               "main":  [
                                                            [
                                                                {
                                                                    "node":  "Build VLM Request",
                                                                    "type":  "main",
                                                                    "index":  0
                                                                }
                                                            ]
                                                        ]
                                           },
                        "Build VLM Request":  {
                                                  "main":  [
                                                               [
                                                                   {
                                                                       "node":  "Call VLM",
                                                                       "type":  "main",
                                                                       "index":  0
                                                                   }
                                                               ]
                                                           ]
                                              },
                        "Call VLM":  {
                                         "main":  [
                                                      [
                                                          {
                                                              "node":  "Handle VLM Response",
                                                              "type":  "main",
                                                              "index":  0
                                                          }
                                                      ]
                                                  ]
                                     },
                        "Handle VLM Response":  {
                                                    "main":  [
                                                                 [
                                                                     {
                                                                         "node":  "Needs Retry?",
                                                                         "type":  "main",
                                                                         "index":  0
                                                                     }
                                                                 ]
                                                             ]
                                                },
                        "Needs Retry?":  {
                                             "main":  [
                                                          [
                                                              {
                                                                  "node":  "Prepare VLM Retry",
                                                                  "type":  "main",
                                                                  "index":  0
                                                              }
                                                          ],
                                                          [
                                                              {
                                                                  "node":  "Merge VLM Results",
                                                                  "type":  "main",
                                                                  "index":  1
                                                              }
                                                          ]
                                                      ]
                                         },
                        "Prepare VLM Retry":  {
                                                  "main":  [
                                                               [
                                                                   {
                                                                       "node":  "Call VLM",
                                                                       "type":  "main",
                                                                       "index":  0
                                                                   }
                                                               ]
                                                           ]
                                              },
                        "Merge VLM Results":  {
                                                  "main":  [
                                                               [
                                                                   {
                                                                       "node":  "Clean for DB",
                                                                       "type":  "main",
                                                                       "index":  0
                                                                   }
                                                               ]
                                                           ]
                                              },
                        "Clean for DB":  {
                                             "main":  [
                                                          [
                                                              {
                                                                  "node":  "Upsert to SQLite",
                                                                  "type":  "main",
                                                                  "index":  0
                                                              }
                                                          ]
                                                      ]
                                         },
                        "Upsert to SQLite":  {
                                                 "main":  [
                                                              [
                                                                  {
                                                                      "node":  "Batch Report",
                                                                      "type":  "main",
                                                                      "index":  0
                                                                  }
                                                              ]
                                                          ]
                                             },
                        "Batch Report":  {
                                             "main":  [
                                                          [
                                                              {
                                                                  "node":  "Webhook Response",
                                                                  "type":  "main",
                                                                  "index":  0
                                                              },
                                                              {
                                                                  "node":  "Has Items for AI?",
                                                                  "type":  "main",
                                                                  "index":  0
                                                              }
                                                          ]
                                                      ]
                                         },
                        "Has Items for AI?":  {
                                                  "main":  [
                                                               [
                                                                   {
                                                                       "node":  "Trigger W2 Captions",
                                                                       "type":  "main",
                                                                       "index":  0
                                                                   }
                                                               ]
                                                           ]
                                              }
                    },
    "settings":  {
                     "executionOrder":  "v1",
                     "callerPolicy":  "workflowsFromSameOwner",
                     "availableInMCP":  true
                 },
    "pinData":  {

                },
    "active":  true,
    "meta":  {

             },
    "tags":  [

             ],
    "versionId":  "e616177f-9a58-4a8a-80d1-f1b99eb9c9b4"
}
